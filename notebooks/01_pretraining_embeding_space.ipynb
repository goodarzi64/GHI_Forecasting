{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Run setup notebook from here\n",
        "!git clone https://github.com/goodarzi64/GHI_Forecasting\n",
        "%run /content/GHI_Forecasting/notebooks/00_colab_setup.ipynb\n"
      ],
      "metadata": {
        "id": "VH9JqdjrR62H",
        "outputId": "039d4ffc-cdbc-4847-e605-8c6ca6003069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VH9JqdjrR62H",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GHI_Forecasting'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 42 (delta 10), reused 37 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (42/42), 2.70 MiB | 18.09 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n",
            "[Errno 2] No such file or directory: 'content/GHI_Forecasting'\n",
            "/content\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.4/768.4 MB\u001b[0m \u001b[31m975.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTorch: 2.6.0+cu124\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric_temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GHI_Forecasting/notebooks\n",
        "!git status"
      ],
      "metadata": {
        "id": "n__7W-QoVye-",
        "outputId": "b88c0e33-575c-4680-8a14-b6e01af211c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "n__7W-QoVye-",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31m../src/__pycache__/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dc6497f4",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "dc6497f4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/GHI_Forecasting\")\n",
        "\n",
        "from src.temporal_autoencoder import pretrain_en_de_with_regularizers\n",
        "\n",
        "# Example usage: pretrain embeddings on temporal tensor\n",
        "# (Assumes temporal_node_tensor and masks are already defined above)\n",
        "model, logs, best_epoch = pretrain_en_de_with_regularizers(\n",
        "    train_tensor=temporal_node_tensor,\n",
        "    val_tensor=None,\n",
        "    in_dim=masks[\"mask_embed\"].sum().item(),\n",
        "    embed_dim=16,\n",
        "    conv_hidden=128,\n",
        "    window=6,\n",
        "    use_attention=True,\n",
        "    batch_size=8,\n",
        "    lr=1e-3,\n",
        "    epochs=20,\n",
        "    device=device,\n",
        "    early_stopping_patience=5,\n",
        "    mask_embed=masks[\"mask_embed\"],\n",
        "    mask_cloud=masks[\"mask_cloud\"],\n",
        "    save_path=None,\n",
        "    verbose=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "071e579f",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "071e579f"
      },
      "outputs": [],
      "source": [
        "from src.cv_splits import make_expanding_folds, extract_fold_data\n",
        "\n",
        "T = temporal_node_tensor.shape[0]\n",
        "first_train_end = int(T * 0.33)\n",
        "val_window = int(T * 0.11)\n",
        "n_folds = 3\n",
        "\n",
        "folds = make_expanding_folds(\n",
        "    T=T,\n",
        "    train_start=0,\n",
        "    first_train_end=first_train_end,\n",
        "    val_window=val_window,\n",
        "    n_folds=n_folds,\n",
        ")\n",
        "\n",
        "print(\"FOLD SPLITS:\")\n",
        "for i, f in enumerate(folds):\n",
        "    print(f\"Fold {i+1}: Train {f['train_slice']}  Val {f['val_slice']}\")\n",
        "\n",
        "train_data, val_data = extract_fold_data(temporal_node_tensor, folds, fold_idx=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4968a2e",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "a4968a2e"
      },
      "outputs": [],
      "source": [
        "from src.hparam_search_encoder import HParamConfig, run_hparam_search, select_best\n",
        "\n",
        "cfg = HParamConfig(\n",
        "    embed_dims=[8, 16, 32],\n",
        "    conv_hiddens=[32, 64, 128, 256],\n",
        "    seeds=[123],\n",
        "    folds=[0, 1, 2],\n",
        "    window=12,\n",
        "    use_attention=True,\n",
        "    batch_size=8,\n",
        "    epochs=20,\n",
        "    lr=1e-3,\n",
        "    early_stopping_patience=5,\n",
        ")\n",
        "\n",
        "results = run_hparam_search(\n",
        "    temporal_node_tensor=temporal_node_tensor,\n",
        "    folds=folds,\n",
        "    mask_embed=masks[\"mask_embed\"].bool().to(device),\n",
        "    mask_cloud=masks[\"mask_cloud\"].bool().to(device),\n",
        "    base_dir=\"/content/gdrive/MyDrive/hparam_search_encoder\",\n",
        "    cfg=cfg,\n",
        "    device=device,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "best_cfg = select_best(results)\n",
        "print(best_cfg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef7c19a",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "fef7c19a"
      },
      "outputs": [],
      "source": [
        "from src.hparam_results import collect_hparam_records, summarize_hparam_results\n",
        "\n",
        "base_dir = \"/content/gdrive/MyDrive/hparam_search_encoder\"\n",
        "df = collect_hparam_records(base_dir)\n",
        "summary = summarize_hparam_results(df)\n",
        "\n",
        "print(summary)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}