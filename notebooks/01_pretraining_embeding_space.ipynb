{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "VH9JqdjrR62H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH9JqdjrR62H",
        "outputId": "1c4ff1f6-f886-4b22-ad4f-e0c5c0d3a6a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 418 bytes | 83.00 KiB/s, done.\n",
            "From https://github.com/goodarzi64/GHI_Forecasting\n",
            "   877064c..f503f1d  main       -> origin/main\n",
            "Updating 877064c..f503f1d\n",
            "Fast-forward\n",
            " src/temporal_autoencoder.py | 5 \u001b[32m+++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 3 insertions(+), 2 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "# Run setup notebook from here\n",
        "!git clone https://github.com/goodarzi64/GHI_Forecasting\n",
        "!git pull\n",
        "%run /content/GHI_Forecasting/notebooks/00_colab_setup.ipynb\n",
        "%run /content/GHI_Forecasting/notebooks/01_import_datasets.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "dc6497f4",
      "metadata": {
        "id": "dc6497f4",
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "608cbf6b-979e-4ee8-e71d-a3fe646f7880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'int' object has no attribute 'normalize'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1625947082.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmask_cloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask_cloud\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m model, logs, best_epoch = ta.pretrain_en_de_with_regularizers(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemporal_node_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mval_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GHI_Forecasting/src/temporal_autoencoder.py\u001b[0m in \u001b[0;36mpretrain_en_de_with_regularizers\u001b[0;34m(train_tensor, val_tensor, in_dim, embed_dim, conv_hidden, window, use_attention, batch_size, lr, epochs, device, early_stopping_patience, mask_embed, mask_cloud, save_path, verbose)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mrecon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_z_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GHI_Forecasting/src/temporal_autoencoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_t)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_cloud_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mz_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mx_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GHI_Forecasting/src/temporal_autoencoder.py\u001b[0m in \u001b[0;36mencode_window\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'normalize'"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "import src.temporal_autoencoder as ta\n",
        "importlib.reload(ta)\n",
        "\n",
        "# make sure tensors are float32 before training\n",
        "temporal_node_tensor = torch.as_tensor(temporal_node_tensor, dtype=torch.float32, device=device)\n",
        "\n",
        "mask_embed = torch.as_tensor(masks[\"mask_embed\"], dtype=torch.bool, device=device)\n",
        "mask_cloud = torch.as_tensor(masks[\"mask_cloud\"], dtype=torch.bool, device=device)\n",
        "\n",
        "model, logs, best_epoch = ta.pretrain_en_de_with_regularizers(\n",
        "    train_tensor=temporal_node_tensor,\n",
        "    val_tensor=None,\n",
        "    in_dim=mask_embed.sum().item(),\n",
        "    embed_dim=16,\n",
        "    conv_hidden=128,\n",
        "    window=6,\n",
        "    use_attention=True,\n",
        "    batch_size=8,\n",
        "    lr=1e-3,\n",
        "    epochs=20,\n",
        "    device=device,\n",
        "    early_stopping_patience=5,\n",
        "    mask_embed=mask_embed,\n",
        "    mask_cloud=mask_cloud,\n",
        "    save_path=None,\n",
        "    verbose=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "071e579f",
      "metadata": {
        "id": "071e579f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from src.cv_splits import make_expanding_folds, extract_fold_data\n",
        "\n",
        "T = temporal_node_tensor.shape[0]\n",
        "first_train_end = int(T * 0.33)\n",
        "val_window = int(T * 0.11)\n",
        "n_folds = 3\n",
        "\n",
        "folds = make_expanding_folds(\n",
        "    T=T,\n",
        "    train_start=0,\n",
        "    first_train_end=first_train_end,\n",
        "    val_window=val_window,\n",
        "    n_folds=n_folds,\n",
        ")\n",
        "\n",
        "print(\"FOLD SPLITS:\")\n",
        "for i, f in enumerate(folds):\n",
        "    print(f\"Fold {i+1}: Train {f['train_slice']}  Val {f['val_slice']}\")\n",
        "\n",
        "train_data, val_data = extract_fold_data(temporal_node_tensor, folds, fold_idx=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4968a2e",
      "metadata": {
        "id": "a4968a2e",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from src.hparam_search_encoder import HParamConfig, run_hparam_search, select_best\n",
        "\n",
        "cfg = HParamConfig(\n",
        "    embed_dims=[8, 16, 32],\n",
        "    conv_hiddens=[32, 64, 128, 256],\n",
        "    seeds=[123],\n",
        "    folds=[0, 1, 2],\n",
        "    window=12,\n",
        "    use_attention=True,\n",
        "    batch_size=8,\n",
        "    epochs=20,\n",
        "    lr=1e-3,\n",
        "    early_stopping_patience=5,\n",
        ")\n",
        "\n",
        "results = run_hparam_search(\n",
        "    temporal_node_tensor=temporal_node_tensor,\n",
        "    folds=folds,\n",
        "    mask_embed=masks[\"mask_embed\"].bool().to(device),\n",
        "    mask_cloud=masks[\"mask_cloud\"].bool().to(device),\n",
        "    base_dir=\"/content/gdrive/MyDrive/hparam_search_encoder\",\n",
        "    cfg=cfg,\n",
        "    device=device,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "best_cfg = select_best(results)\n",
        "print(best_cfg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef7c19a",
      "metadata": {
        "id": "fef7c19a",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from src.hparam_results import collect_hparam_records, summarize_hparam_results\n",
        "\n",
        "base_dir = \"/content/gdrive/MyDrive/hparam_search_encoder\"\n",
        "df = collect_hparam_records(base_dir)\n",
        "summary = summarize_hparam_results(df)\n",
        "\n",
        "print(summary)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}