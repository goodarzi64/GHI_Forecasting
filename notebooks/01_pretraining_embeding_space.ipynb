{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "VH9JqdjrR62H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH9JqdjrR62H",
        "outputId": "8a2e0265-b4df-4af9-9511-c9feb1bb22de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "# Run setup notebook from here\n",
        "!git clone https://github.com/goodarzi64/GHI_Forecasting\n",
        "%cd GHI_Forecasting\n",
        "!git pull\n",
        "%run /content/GHI_Forecasting/notebooks/00_colab_setup.ipynb\n",
        "%run /content/GHI_Forecasting/notebooks/01_import_datasets.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dc6497f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "dc6497f4",
        "outputId": "a19bf688-9b5a-42b2-c723-60a194fda414",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1625947082.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmask_cloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask_cloud\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m model, logs, best_epoch = ta.pretrain_en_de_with_regularizers(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemporal_node_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mval_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GHI_Forecasting/src/temporal_autoencoder.py\u001b[0m in \u001b[0;36mpretrain_en_de_with_regularizers\u001b[0;34m(train_tensor, val_tensor, in_dim, embed_dim, conv_hidden, window, use_attention, batch_size, lr, epochs, device, early_stopping_patience, mask_embed, mask_cloud, save_path, verbose)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mrecon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_z_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GHI_Forecasting/src/temporal_autoencoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_t)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_cloud_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mz_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mx_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GHI_Forecasting/src/temporal_autoencoder.py\u001b[0m in \u001b[0;36mencode_window\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mz_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mattn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     return (\n\u001b[0;32m-> 1425\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m     )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "import src.temporal_autoencoder as ta\n",
        "importlib.reload(ta)\n",
        "\n",
        "# make sure tensors are float32 before training\n",
        "temporal_node_tensor = torch.as_tensor(temporal_node_tensor, dtype=torch.float32, device=device)\n",
        "\n",
        "mask_embed = torch.as_tensor(masks[\"mask_embed\"], dtype=torch.bool, device=device)\n",
        "mask_cloud = torch.as_tensor(masks[\"mask_cloud\"], dtype=torch.bool, device=device)\n",
        "\n",
        "model, logs, best_epoch = ta.pretrain_en_de_with_regularizers(\n",
        "    train_tensor=temporal_node_tensor,\n",
        "    val_tensor=None,\n",
        "    in_dim=mask_embed.sum().item(),\n",
        "    embed_dim=16,\n",
        "    conv_hidden=128,\n",
        "    window=6,\n",
        "    use_attention=True,\n",
        "    batch_size=8,\n",
        "    lr=1e-3,\n",
        "    epochs=20,\n",
        "    device=device,\n",
        "    early_stopping_patience=5,\n",
        "    mask_embed=mask_embed,\n",
        "    mask_cloud=mask_cloud,\n",
        "    save_path=None,\n",
        "    verbose=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "071e579f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "071e579f",
        "outputId": "0a1dd884-1d88-44f6-b7d0-eb37fba42e84",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD SPLITS:\n",
            "Fold 1: Train (0, 7588)  Val (7588, 10117)\n",
            "Fold 2: Train (0, 10117)  Val (10117, 12646)\n",
            "Fold 3: Train (0, 12646)  Val (12646, 15175)\n"
          ]
        }
      ],
      "source": [
        "from src.cv_splits import make_expanding_folds, extract_fold_data\n",
        "\n",
        "T = temporal_node_tensor.shape[0]\n",
        "first_train_end = int(T * 0.33)\n",
        "val_window = int(T * 0.11)\n",
        "n_folds = 3\n",
        "\n",
        "folds = make_expanding_folds(\n",
        "    T=T,\n",
        "    train_start=0,\n",
        "    first_train_end=first_train_end,\n",
        "    val_window=val_window,\n",
        "    n_folds=n_folds,\n",
        ")\n",
        "\n",
        "print(\"FOLD SPLITS:\")\n",
        "for i, f in enumerate(folds):\n",
        "    print(f\"Fold {i+1}: Train {f['train_slice']}  Val {f['val_slice']}\")\n",
        "\n",
        "train_data, val_data = extract_fold_data(temporal_node_tensor, folds, fold_idx=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a4968a2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4968a2e",
        "outputId": "45f4cf98-4078-4cb9-d659-e44f15c4a848",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing embed_dim=8, conv_hidden=32\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0692 | Val: 0.0205 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch32_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0205\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0568 | Val: 0.0089 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch32_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0089\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0429 | Val: 0.0126 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch32_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0126\n",
            "  mean=0.0140 ± 0.0059\n",
            "\n",
            "Testing embed_dim=8, conv_hidden=64\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0542 | Val: 0.0198 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch64_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0198\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0370 | Val: 0.0056 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch64_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0056\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0360 | Val: 0.0097 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch64_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0097\n",
            "  mean=0.0117 ± 0.0073\n",
            "\n",
            "Testing embed_dim=8, conv_hidden=128\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0551 | Val: 0.0212 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch128_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0212\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0459 | Val: 0.0132 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch128_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0132\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0286 | Val: 0.0084 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch128_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0084\n",
            "  mean=0.0142 ± 0.0064\n",
            "\n",
            "Testing embed_dim=8, conv_hidden=256\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0437 | Val: 0.0224 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch256_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0224\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0278 | Val: 0.0053 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch256_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0053\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0439 | Val: 0.0374 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed8_ch256_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0374\n",
            "  mean=0.0217 ± 0.0161\n",
            "\n",
            "Testing embed_dim=16, conv_hidden=32\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0720 | Val: 0.0146 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch32_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0146\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0547 | Val: 0.0064 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch32_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0064\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0393 | Val: 0.0150 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch32_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0150\n",
            "  mean=0.0120 ± 0.0048\n",
            "\n",
            "Testing embed_dim=16, conv_hidden=64\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0526 | Val: 0.0137 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch64_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0137\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0418 | Val: 0.0059 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch64_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0059\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0362 | Val: 0.0088 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch64_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0088\n",
            "  mean=0.0095 ± 0.0039\n",
            "\n",
            "Testing embed_dim=16, conv_hidden=128\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0487 | Val: 0.0094 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch128_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0094\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0338 | Val: 0.0052 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch128_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0052\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0276 | Val: 0.0079 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch128_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0079\n",
            "  mean=0.0075 ± 0.0021\n",
            "\n",
            "Testing embed_dim=16, conv_hidden=256\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0438 | Val: 0.0106 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch256_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0106\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0365 | Val: 0.0080 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch256_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0080\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0297 | Val: 0.0089 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed16_ch256_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0089\n",
            "  mean=0.0092 ± 0.0013\n",
            "\n",
            "Testing embed_dim=32, conv_hidden=32\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0654 | Val: 0.0139 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch32_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0139\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0622 | Val: 0.0076 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch32_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0076\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0383 | Val: 0.0148 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch32_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0148\n",
            "  mean=0.0121 ± 0.0039\n",
            "\n",
            "Testing embed_dim=32, conv_hidden=64\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0558 | Val: 0.0109 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch64_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0109\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0395 | Val: 0.0045 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch64_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0045\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0360 | Val: 0.0101 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch64_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0101\n",
            "  mean=0.0085 ± 0.0035\n",
            "\n",
            "Testing embed_dim=32, conv_hidden=128\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0476 | Val: 0.0129 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch128_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0129\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0336 | Val: 0.0051 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch128_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0051\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0249 | Val: 0.0113 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch128_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0113\n",
            "  mean=0.0098 ± 0.0041\n",
            "\n",
            "Testing embed_dim=32, conv_hidden=256\n",
            "  Seed 123\n",
            "    Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0455 | Val: 0.0134 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch256_seed123_fold1.pt (epoch 1)\n",
            "      best val = 0.0134\n",
            "    Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0279 | Val: 0.0053 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch256_seed123_fold2.pt (epoch 1)\n",
            "      best val = 0.0053\n",
            "    Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train: 0.0253 | Val: 0.0098 | Patience 0\n",
            "Training complete. Best model saved at /content/gdrive/MyDrive/hparam_search_encoder/ed32_ch256_seed123_fold3.pt (epoch 1)\n",
            "      best val = 0.0098\n",
            "  mean=0.0095 ± 0.0040\n",
            "{'embed_dim': 16.0, 'conv_hidden': 128.0, 'val_mean': 0.007522242062432482, 'val_std': 0.0021406918972927463}\n"
          ]
        }
      ],
      "source": [
        "from src.hparam_search_encoder import HParamConfig, run_hparam_search, select_best\n",
        "\n",
        "cfg = HParamConfig(\n",
        "    embed_dims=[8, 16, 32],\n",
        "    conv_hiddens=[32, 64, 128, 256],\n",
        "    seeds=[123],\n",
        "    folds=[0, 1, 2],\n",
        "    window=12,\n",
        "    use_attention=True,\n",
        "    batch_size=8,\n",
        "    epochs=1,\n",
        "    lr=1e-3,\n",
        "    early_stopping_patience=5,\n",
        ")\n",
        "\n",
        "mask_embed = torch.as_tensor(masks[\"mask_embed\"], dtype=torch.bool, device=device)\n",
        "mask_cloud = torch.as_tensor(masks[\"mask_cloud\"], dtype=torch.bool, device=device)\n",
        "\n",
        "results = run_hparam_search(\n",
        "    temporal_node_tensor=temporal_node_tensor,\n",
        "    folds=folds,\n",
        "    mask_embed=mask_embed,\n",
        "    mask_cloud=mask_cloud,\n",
        "    base_dir=\"/content/gdrive/MyDrive/hparam_search_encoder\",\n",
        "    cfg=cfg,\n",
        "    device=device,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "\n",
        "best_cfg = select_best(results)\n",
        "print(best_cfg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fef7c19a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fef7c19a",
        "outputId": "71dc41c6-520b-43d6-e4b7-e6015cb531dc",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    embed_dim  conv_hidden  val_mean   val_std  n_runs\n",
            "6          16          128  0.007522  0.002141       3\n",
            "9          32           64  0.008518  0.003507       3\n",
            "7          16          256  0.009155  0.001284       3\n",
            "5          16           64  0.009469  0.003935       3\n",
            "11         32          256  0.009513  0.004044       3\n",
            "10         32          128  0.009769  0.004113       3\n",
            "1           8           64  0.011697  0.007318       3\n",
            "4          16           32  0.012035  0.004845       3\n",
            "8          32           32  0.012143  0.003920       3\n",
            "0           8           32  0.014002  0.005891       3\n",
            "2           8          128  0.014244  0.006438       3\n",
            "3           8          256  0.021709  0.016053       3\n"
          ]
        }
      ],
      "source": [
        "from src.hparam_results import collect_hparam_records, summarize_hparam_results\n",
        "\n",
        "base_dir = \"/content/gdrive/MyDrive/hparam_search_encoder\"\n",
        "df = collect_hparam_records(base_dir)\n",
        "summary = summarize_hparam_results(df)\n",
        "\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dfa1789",
      "metadata": {},
      "source": [
        "diversity metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cabc9da",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Link to src/hparam_metrics.py\n",
        "from src.temporal_autoencoder import TemporalWindowAutoEncoder\n",
        "from src.hparam_metrics import share_metric_temporal\n",
        "\n",
        "# ============================================================\n",
        "# === 0. Configuration =======================================\n",
        "# ============================================================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# === Paths to all models you want to compare ===\n",
        "ckpt_paths = [\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed8_ch256_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed8_ch128_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed8_ch64_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed8_ch32_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed16_ch256_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed16_ch128_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed16_ch64_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed16_ch32_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed32_ch256_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed32_ch128_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed32_ch64_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed32_ch32_seed123_fold3.pt\",\n",
        "]\n",
        "\n",
        "# === Mask for feature selection (kept as before) ===\n",
        "mask_embed = torch.tensor(masks[\"mask_embed\"], dtype=torch.bool, device=device)\n",
        "\n",
        "# ============================================================\n",
        "# === Helper: create sliding windows =========================\n",
        "# ============================================================\n",
        "def sliding_windows(x, window):\n",
        "    \"\"\"Generate sliding temporal windows [B, W, N, F].\"\"\"\n",
        "    x = x[..., mask_embed]\n",
        "    return torch.stack([x[t:t + window] for t in range(len(x) - window)], dim=0)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# ===  Extract Fold-3 Validation Data  =========\n",
        "# ---------------------------------------------\n",
        "fold_index = 2   # fold3 because fold indices = [0,1,2]\n",
        "\n",
        "_, val_data_f3 = extract_fold_data(\n",
        "    temporal_node_tensor,\n",
        "    folds,\n",
        "    fold_index\n",
        ")\n",
        "val_data_f3 = torch.as_tensor(val_data_f3, dtype=torch.float32, device=device)\n",
        "\n",
        "# ============================================================\n",
        "# === 1. Evaluate each model =================================\n",
        "# ============================================================\n",
        "\n",
        "results = []\n",
        "\n",
        "for ckpt_path in ckpt_paths:\n",
        "    print(f\"\\n>>> Evaluating {ckpt_path}\")\n",
        "\n",
        "    # --- Load checkpoint ---\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "    config = ckpt.get(\"config\", {})\n",
        "\n",
        "    # === Cloud embedding safety ===\n",
        "    # If training config did not store mask_cloud, you must pass it manually\n",
        "    config[\"mask_cloud\"] = masks.get(\"mask_cloud\", None)\n",
        "    if config[\"mask_cloud\"] is not None and not isinstance(config[\"mask_cloud\"], torch.Tensor):\n",
        "        config[\"mask_cloud\"] = torch.tensor(config[\"mask_cloud\"], dtype=torch.bool)\n",
        "\n",
        "    # === Instantiate model with current API ===\n",
        "    model = TemporalWindowAutoEncoder(\n",
        "        in_dim=config[\"in_dim\"],\n",
        "        embed_dim=config[\"embed_dim\"],\n",
        "        window=config.get(\"window\", 6),\n",
        "        conv_hidden=config.get(\"conv_hidden\", 64),\n",
        "        dropout=config.get(\"dropout\", 0.1),\n",
        "        use_attention=config.get(\"use_attention\", False),\n",
        "        cloud_embed_dim=config.get(\"cloud_embed_dim\", 3),\n",
        "        mask_cloud=config.get(\"mask_cloud\", None),\n",
        "    ).to(device)\n",
        "\n",
        "    # --- Load weights ---\n",
        "    missing, unexpected = model.load_state_dict(ckpt[\"model_state\"], strict=False)\n",
        "    if missing or unexpected:\n",
        "        print(f\"ℹ️ State dict load: missing={len(missing)}, unexpected={len(unexpected)}\")\n",
        "\n",
        "    model.eval()\n",
        "    window = config[\"window\"]\n",
        "\n",
        "    # --- Prepare validation windows ---\n",
        "    val_seq = sliding_windows(val_data_f3.to(device), window=window)\n",
        "    val_loader = torch.utils.data.DataLoader(val_seq, batch_size=8, shuffle=False)\n",
        "\n",
        "    # --- Compute metrics ---\n",
        "    metrics_all = []\n",
        "    with torch.no_grad():\n",
        "        for x_t in val_loader:\n",
        "            x_t = x_t.to(device)\n",
        "            _, z_t = model(x_t)\n",
        "            metrics = share_metric_temporal(x_t, z_t)\n",
        "            metrics_all.append(metrics)\n",
        "\n",
        "    # === Aggregate overall metrics ===\n",
        "    mean_input = torch.tensor([m[\"share_input\"] for m in metrics_all]).mean().item()\n",
        "    mean_embed = torch.tensor([m[\"share_embed\"] for m in metrics_all]).mean().item()\n",
        "    mean_delta = mean_embed - mean_input\n",
        "\n",
        "    # === Aggregate mean component metrics ===\n",
        "    mean_eff_rank_in  = torch.tensor([m[\"mean_details\"][\"eff_rank_in\"]  for m in metrics_all]).mean().item()\n",
        "    mean_cos_div_in   = torch.tensor([m[\"mean_details\"][\"cos_div_in\"]   for m in metrics_all]).mean().item()\n",
        "    mean_rel_var_in   = torch.tensor([m[\"mean_details\"][\"rel_var_in\"]   for m in metrics_all]).mean().item()\n",
        "\n",
        "    mean_eff_rank_out = torch.tensor([m[\"mean_details\"][\"eff_rank_out\"] for m in metrics_all]).mean().item()\n",
        "    mean_cos_div_out  = torch.tensor([m[\"mean_details\"][\"cos_div_out\"]  for m in metrics_all]).mean().item()\n",
        "    mean_rel_var_out  = torch.tensor([m[\"mean_details\"][\"rel_var_out\"]  for m in metrics_all]).mean().item()\n",
        "\n",
        "    results.append({\n",
        "        \"model\": ckpt_path.split(\"/\")[-1].replace(\".pt\", \"\"),\n",
        "        \"share_input\": mean_input,\n",
        "        \"share_embed\": mean_embed,\n",
        "        \"delta\": mean_delta,\n",
        "        \"r_in\": mean_eff_rank_in,\n",
        "        \"c_in\": mean_cos_div_in,\n",
        "        \"v_in\": mean_rel_var_in,\n",
        "        \"r_out\": mean_eff_rank_out,\n",
        "        \"c_out\": mean_cos_div_out,\n",
        "        \"v_out\": mean_rel_var_out,\n",
        "        \"attention\": config.get(\"use_attention\", False)\n",
        "    })\n",
        "\n",
        "# ============================================================\n",
        "# === 2. Display Comparison ==================================\n",
        "# ============================================================\n",
        "df = pd.DataFrame(results)\n",
        "df = df.round(4)\n",
        "df = df.sort_values(\"delta\", ascending=False)\n",
        "\n",
        "print(\"\\n=== Representation Diversity Comparison ===\")\n",
        "print(df[[\n",
        "    \"model\", \"attention\", \"share_input\", \"share_embed\", \"delta\",\n",
        "    \"r_in\", \"c_in\", \"v_in\", \"r_out\", \"c_out\", \"v_out\"\n",
        "]].to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
