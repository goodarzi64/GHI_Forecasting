{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VH9JqdjrR62H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH9JqdjrR62H",
        "outputId": "8a2e0265-b4df-4af9-9511-c9feb1bb22de"
      },
      "outputs": [],
      "source": [
        "# Run setup notebook from here\n",
        "!git clone https://github.com/goodarzi64/GHI_Forecasting\n",
        "%cd GHI_Forecasting\n",
        "!git pull\n",
        "%run /content/GHI_Forecasting/notebooks/00_colab_setup.ipynb\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "%run /content/GHI_Forecasting/notebooks/01_import_datasets.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc6497f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "dc6497f4",
        "outputId": "a19bf688-9b5a-42b2-c723-60a194fda414"
      },
      "outputs": [],
      "source": [
        "from src.temporal_autoencoder import pretrain_en_de_with_regularizers\n",
        "\n",
        "# make sure tensors are float32 before training\n",
        "temporal_node_tensor = torch.as_tensor(temporal_node_tensor, dtype=torch.float32, device=device)\n",
        "\n",
        "mask_embed = torch.as_tensor(masks[\"mask_embed\"], dtype=torch.bool, device=device)\n",
        "mask_cloud = torch.as_tensor(masks[\"mask_cloud\"], dtype=torch.bool, device=device)\n",
        "\n",
        "model, logs, best_epoch = pretrain_en_de_with_regularizers(\n",
        "    train_tensor=temporal_node_tensor,\n",
        "    val_tensor=None,\n",
        "    in_dim=mask_embed.sum().item(),\n",
        "    embed_dim=16,\n",
        "    conv_hidden=128,\n",
        "    window=6,\n",
        "    use_attention=True,\n",
        "    batch_size=8,\n",
        "    lr=1e-3,\n",
        "    epochs=20,\n",
        "    device=device,\n",
        "    early_stopping_patience=5,\n",
        "    mask_embed=mask_embed,\n",
        "    mask_cloud=mask_cloud,\n",
        "    save_path=None,\n",
        "    verbose=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "071e579f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "071e579f",
        "outputId": "0a1dd884-1d88-44f6-b7d0-eb37fba42e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD SPLITS:\n",
            "Fold 1: Train (0, 7588)  Val (7588, 10117)\n",
            "Fold 2: Train (0, 10117)  Val (10117, 12646)\n",
            "Fold 3: Train (0, 12646)  Val (12646, 15175)\n"
          ]
        }
      ],
      "source": [
        "from src.cv_splits import make_expanding_folds, extract_fold_data\n",
        "\n",
        "T = temporal_node_tensor.shape[0]\n",
        "first_train_end = int(T * 0.33)\n",
        "val_window = int(T * 0.11)\n",
        "n_folds = 3\n",
        "\n",
        "folds = make_expanding_folds(\n",
        "    T=T,\n",
        "    train_start=0,\n",
        "    first_train_end=first_train_end,\n",
        "    val_window=val_window,\n",
        "    n_folds=n_folds,\n",
        ")\n",
        "\n",
        "print(\"FOLD SPLITS:\")\n",
        "for i, f in enumerate(folds):\n",
        "    print(f\"Fold {i+1}: Train {f['train_slice']}  Val {f['val_slice']}\")\n",
        "\n",
        "train_data, val_data = extract_fold_data(temporal_node_tensor, folds, fold_idx=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4968a2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4968a2e",
        "outputId": "45f4cf98-4078-4cb9-d659-e44f15c4a848"
      },
      "outputs": [],
      "source": [
        "from src.hparam_search_encoder import HParamConfig, run_hparam_search, select_best\n",
        "\n",
        "cfg = HParamConfig(\n",
        "    embed_dims=[8, 16, 32],\n",
        "    conv_hiddens=[32, 64, 128, 256],\n",
        "    seeds=[123],\n",
        "    folds=[0, 1, 2],\n",
        "    window=12,\n",
        "    use_attention=True,\n",
        "    batch_size=8,\n",
        "    epochs=1,\n",
        "    lr=1e-3,\n",
        "    early_stopping_patience=5,\n",
        ")\n",
        "\n",
        "mask_embed = torch.as_tensor(masks[\"mask_embed\"], dtype=torch.bool, device=device)\n",
        "mask_cloud = torch.as_tensor(masks[\"mask_cloud\"], dtype=torch.bool, device=device)\n",
        "\n",
        "results = run_hparam_search(\n",
        "    temporal_node_tensor=temporal_node_tensor,\n",
        "    folds=folds,\n",
        "    mask_embed=mask_embed,\n",
        "    mask_cloud=mask_cloud,\n",
        "    base_dir=\"/content/gdrive/MyDrive/hparam_search_encoder\",\n",
        "    cfg=cfg,\n",
        "    device=device,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "\n",
        "best_cfg = select_best(results)\n",
        "print(best_cfg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef7c19a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fef7c19a",
        "outputId": "71dc41c6-520b-43d6-e4b7-e6015cb531dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    embed_dim  conv_hidden  val_mean   val_std  n_runs\n",
            "6          16          128  0.007522  0.002141       3\n",
            "9          32           64  0.008518  0.003507       3\n",
            "7          16          256  0.009155  0.001284       3\n",
            "5          16           64  0.009469  0.003935       3\n",
            "11         32          256  0.009513  0.004044       3\n",
            "10         32          128  0.009769  0.004113       3\n",
            "1           8           64  0.011697  0.007318       3\n",
            "4          16           32  0.012035  0.004845       3\n",
            "8          32           32  0.012143  0.003920       3\n",
            "0           8           32  0.014002  0.005891       3\n",
            "2           8          128  0.014244  0.006438       3\n",
            "3           8          256  0.021709  0.016053       3\n"
          ]
        }
      ],
      "source": [
        "from src.hparam_results import collect_hparam_records, summarize_hparam_results\n",
        "\n",
        "base_dir = \"/content/gdrive/MyDrive/hparam_search_encoder\"\n",
        "df = collect_hparam_records(base_dir)\n",
        "summary = summarize_hparam_results(df)\n",
        "\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dfa1789",
      "metadata": {},
      "source": [
        "diversity metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cabc9da",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Link to src/hparam_metrics.py\n",
        "import pandas as pd\n",
        "from src.temporal_autoencoder import TemporalWindowAutoEncoder\n",
        "from src.hparam_metrics import share_metric_temporal\n",
        "\n",
        "# ============================================================\n",
        "# === 0. Configuration =======================================\n",
        "# ============================================================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# === Paths to all models you want to compare ===\n",
        "ckpt_paths = [\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed8_ch256_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed8_ch128_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed8_ch64_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed8_ch32_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed16_ch256_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed16_ch128_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed16_ch64_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed16_ch32_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed32_ch256_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed32_ch128_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed32_ch64_seed123_fold3.pt\",\n",
        "    \"/content/gdrive/MyDrive/hparam_search_encoder/ed32_ch32_seed123_fold3.pt\",\n",
        "]\n",
        "\n",
        "# === Mask for feature selection (kept as before) ===\n",
        "mask_embed = torch.tensor(masks[\"mask_embed\"], dtype=torch.bool, device=device)\n",
        "\n",
        "# ============================================================\n",
        "# === Helper: create sliding windows =========================\n",
        "# ============================================================\n",
        "def sliding_windows(x, window):\n",
        "    \"\"\"Generate sliding temporal windows [B, W, N, F].\"\"\"\n",
        "    x = x[..., mask_embed]\n",
        "    return torch.stack([x[t:t + window] for t in range(len(x) - window)], dim=0)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# ===  Extract Fold-3 Validation Data  =========\n",
        "# ---------------------------------------------\n",
        "fold_index = 2   # fold3 because fold indices = [0,1,2]\n",
        "\n",
        "_, val_data_f3 = extract_fold_data(\n",
        "    temporal_node_tensor,\n",
        "    folds,\n",
        "    fold_index\n",
        ")\n",
        "val_data_f3 = torch.as_tensor(val_data_f3, dtype=torch.float32, device=device)\n",
        "\n",
        "# ============================================================\n",
        "# === 1. Evaluate each model =================================\n",
        "# ============================================================\n",
        "\n",
        "results = []\n",
        "\n",
        "for ckpt_path in ckpt_paths:\n",
        "    print(f\"\\n>>> Evaluating {ckpt_path}\")\n",
        "\n",
        "    # --- Load checkpoint ---\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "    config = ckpt.get(\"config\", {})\n",
        "\n",
        "    # === Cloud embedding safety ===\n",
        "    # If training config did not store mask_cloud, you must pass it manually\n",
        "    config[\"mask_cloud\"] = masks.get(\"mask_cloud\", None)\n",
        "    if config[\"mask_cloud\"] is not None and not isinstance(config[\"mask_cloud\"], torch.Tensor):\n",
        "        config[\"mask_cloud\"] = torch.tensor(config[\"mask_cloud\"], dtype=torch.bool)\n",
        "\n",
        "    # === Instantiate model with current API ===\n",
        "    model = TemporalWindowAutoEncoder(\n",
        "        in_dim=config[\"in_dim\"],\n",
        "        embed_dim=config[\"embed_dim\"],\n",
        "        window=config.get(\"window\", 6),\n",
        "        conv_hidden=config.get(\"conv_hidden\", 64),\n",
        "        dropout=config.get(\"dropout\", 0.1),\n",
        "        use_attention=config.get(\"use_attention\", False),\n",
        "        cloud_embed_dim=config.get(\"cloud_embed_dim\", 3),\n",
        "        mask_cloud=config.get(\"mask_cloud\", None),\n",
        "    ).to(device)\n",
        "\n",
        "    # --- Load weights ---\n",
        "    missing, unexpected = model.load_state_dict(ckpt[\"model_state\"], strict=False)\n",
        "    if missing or unexpected:\n",
        "        print(f\"ℹ️ State dict load: missing={len(missing)}, unexpected={len(unexpected)}\")\n",
        "\n",
        "    model.eval()\n",
        "    window = config[\"window\"]\n",
        "\n",
        "    # --- Prepare validation windows ---\n",
        "    val_seq = sliding_windows(val_data_f3.to(device), window=window)\n",
        "    val_loader = torch.utils.data.DataLoader(val_seq, batch_size=8, shuffle=False)\n",
        "\n",
        "    # --- Compute metrics ---\n",
        "    metrics_all = []\n",
        "    with torch.no_grad():\n",
        "        for x_t in val_loader:\n",
        "            x_t = x_t.to(device)\n",
        "            _, z_t = model(x_t)\n",
        "            metrics = share_metric_temporal(x_t, z_t)\n",
        "            metrics_all.append(metrics)\n",
        "\n",
        "    # === Aggregate overall metrics ===\n",
        "    mean_input = torch.tensor([m[\"share_input\"] for m in metrics_all]).mean().item()\n",
        "    mean_embed = torch.tensor([m[\"share_embed\"] for m in metrics_all]).mean().item()\n",
        "    mean_delta = mean_embed - mean_input\n",
        "\n",
        "    # === Aggregate mean component metrics ===\n",
        "    mean_eff_rank_in  = torch.tensor([m[\"mean_details\"][\"eff_rank_in\"]  for m in metrics_all]).mean().item()\n",
        "    mean_cos_div_in   = torch.tensor([m[\"mean_details\"][\"cos_div_in\"]   for m in metrics_all]).mean().item()\n",
        "    mean_rel_var_in   = torch.tensor([m[\"mean_details\"][\"rel_var_in\"]   for m in metrics_all]).mean().item()\n",
        "\n",
        "    mean_eff_rank_out = torch.tensor([m[\"mean_details\"][\"eff_rank_out\"] for m in metrics_all]).mean().item()\n",
        "    mean_cos_div_out  = torch.tensor([m[\"mean_details\"][\"cos_div_out\"]  for m in metrics_all]).mean().item()\n",
        "    mean_rel_var_out  = torch.tensor([m[\"mean_details\"][\"rel_var_out\"]  for m in metrics_all]).mean().item()\n",
        "\n",
        "    results.append({\n",
        "        \"model\": ckpt_path.split(\"/\")[-1].replace(\".pt\", \"\"),\n",
        "        \"share_input\": mean_input,\n",
        "        \"share_embed\": mean_embed,\n",
        "        \"delta\": mean_delta,\n",
        "        \"r_in\": mean_eff_rank_in,\n",
        "        \"c_in\": mean_cos_div_in,\n",
        "        \"v_in\": mean_rel_var_in,\n",
        "        \"r_out\": mean_eff_rank_out,\n",
        "        \"c_out\": mean_cos_div_out,\n",
        "        \"v_out\": mean_rel_var_out,\n",
        "        \"attention\": config.get(\"use_attention\", False)\n",
        "    })\n",
        "\n",
        "# ============================================================\n",
        "# === 2. Display Comparison ==================================\n",
        "# ============================================================\n",
        "df = pd.DataFrame(results)\n",
        "df = df.round(4)\n",
        "df = df.sort_values(\"delta\", ascending=False)\n",
        "\n",
        "print(\"\\n=== Representation Diversity Comparison ===\")\n",
        "print(df[[\n",
        "    \"model\", \"attention\", \"share_input\", \"share_embed\", \"delta\",\n",
        "    \"r_in\", \"c_in\", \"v_in\", \"r_out\", \"c_out\", \"v_out\"\n",
        "]].to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
